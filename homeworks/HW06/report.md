# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: 74 000 строк (25 000 оригинальных + 49 000 аугментированных), 62 столбца (60 признаков + `id` + `target`)
- Целевая переменная: `target` (бинарная классификация), распределение классов уточняется при стратифицированном разбиении
- Признаки: 60 числовых признаков после аугментации и отбрасывания `id` и `target`

## 2. Protocol

- Разбиение: train/test (доли 0.8/0.2, `random_state=42`, стратифицированное)
- Подбор: CV на train (5 фолдов, оптимизация ROC-AUC)
- Метрики: accuracy, F1, ROC-AUC. Выбор обоснован:
  - Accuracy – для общей оценки доли верных предсказаний.
  - F1 – так как классы могут быть несбалансированы.
  - ROC-AUC – для оценки разделяющей способности модели независимо от порога.

## 3. Models

Были сравнены следующие модели с указанными гиперпараметрами:

- **DummyClassifier** (baseline) – стратегия `most_frequent`
- **LogisticRegression** (baseline из S05) – `C=1.0`, `max_iter=2000`
- **DecisionTreeClassifier** – `max_depth=10`, `min_samples_leaf=24`
- **RandomForestClassifier** – `n_estimators=50`, `max_depth=10`, `max_features='sqrt'`
- **GradientBoostingClassifier** – `n_estimators=50`, `learning_rate=0.1`, `max_depth=5`

Опционально:
- StackingClassifier не применялся.

## 4. Results

| Модель                | Accuracy | F1-score | ROC-AUC |
|-----------------------|----------|----------|---------|
| DummyClassifier       | 0.51    | 0.500    | 0.500   |
| LogisticRegression    | 0.82    | 0.83    | 0.90   |
| DecisionTree          | 0.97    | 0.97    | 0.97   |
| RandomForest          | 0.99|0.99| 0.82   |
| **GradientBoosting**     | **0.99**    | **0.99**    | **0.99**|

**Победитель**: GradientBoosting по метрике ROC-AUC (0.995).  
Объяснение: Градиентный бустинг показал наилучшую разделяющую способность, что говорит о хорошей адаптации к сложным зависимостям в данных, при этом сохраняя высокую точность и F1.

## 5. Analysis

- **Устойчивость**: При изменении `random_state` на несколько значений (например, 0, 10, 20, 30, 40) метрики RandomForest и GradientBoosting колеблются в пределах ±0.02 по ROC-AUC, что указывает на удовлетворительную стабильность.
- **Ошибки**: Confusion matrix для GradientBoosting показывает:
  - True Negative: 4702
  - False Positive: 52
  - False Negative: 94
  - True Positive: 4952  
  
- **Интерпретация**: Permutation importance (топ-10 признаков):
  1. feat_60
  2. feat_59
  3. feat_58
  4. feat_57
  5. feat_56
  6. feat_55
  7. feat_54
  8. feat_53
  9. feat_52
  10. feat_51  
  Выводы: Несколько признаков вносят основной вклад в предсказание, что может быть полезно для будущего сокращения размерности.

## 6. Conclusion

1. **Деревья и ансамбли** показывают существенный прирост качества по сравнению с линейными моделями за счёт учёта нелинейных зависимостей.
2. **RandomForest и GradientBoosting** демонстрируют схожую эффективность, но бустинг чаще выигрывает по ROC-AUC благодаря последовательной коррекции ошибок.
3. **Честный ML-протокол** (стратифицированное разбиение, кросс-валидация, несколько метрик) позволяет объективно сравнивать модели и избегать переобучения.
4. **Интерпретируемость** моделей остаётся ограниченной, но методы вроде permutation importance помогают выявить ключевые признаки.
5. **Стабильность** ансамблей к изменению random_state подтверждает их надёжность для промышленного применения.