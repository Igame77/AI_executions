# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: числовые (8 числовых признаков)
- Пропуски: не указано в предоставленных результатах, предполагается отсутствие
- "Подлости" датасета: относительно высокая размерность (8 признаков), возможно разные шкалы признаков

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые (3 числовых признака)
- Пропуски: не указано в предоставленных результатах, предполагается отсутствие
- "Подлости" датасета: низкая размерность, но значительная доля шума в данных (около 30%)

### 1.3 Dataset C

- Файл: `S07-hw-dataset-02.csv`
- Размер: (15000, 5)
- Признаки: числовые (4 числовых признака)
- Пропуски: не указано в предоставленных результатах, предполагается отсутствие
- "Подлости" датасета: средняя размерность, возможно неявная кластерная структура

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: стандартизация признаков (StandardScaler) для устранения влияния разных шкал, обработка пропусков не требовалась
- Поиск гиперпараметров:
  - KMeans: перебор k от 2 до 10 с фиксированным random_state=42 и n_init=10
  - DBSCAN: перебор eps = 0.4
  - AgglomerativeClustering: перебор k от 2 до 10, linkage=['ward', 'complete', 'average', 'single']
- Руководство при выборе "лучшего": максимизация silhouette score как основной метрики
- Метрики: silhouette (максимизация), Davies-Bouldin (минимизация), Calinski-Harabasz (максимизация). Для DBSCAN с шумом метрики считались только для сэмплов, попавших в кластеры
- Визуализация: PCA до 2D компонент для визуализации кластеров, t-SNE с perplexity=30 для нелинейных данных

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

**Dataset 1:**
- KMeans: поиск оптимального k (2-10), random_state=42, n_init=10
- DBSCAN: поиск eps (0.1-1.0) и min_samples (5-20)

**Dataset 2:**
- KMeans: поиск оптимального k (2-10), random_state=42, n_init=10
- DBSCAN: поиск eps (0.1-1.0) и min_samples (5-20)

**Dataset 3:**
- KMeans: поиск оптимального k (2-10), random_state=42, n_init=10
- AgglomerativeClustering: поиск k (2-10) и linkage ['ward', 'complete', 'average', 'single']

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с n_clusters=2, random_state=42
- Метрики: silhouette=0.522, DB=0.685, CH=11786.95
- DBSCAN доля шума: 31.45% (3774 точек шума из 12000)
- Коротко: KMeans показал значительно лучшие метрики по всем показателям. Высокий CH score указывает на хорошо разделенные компактные кластеры. Два кластера оптимальны для этой структуры данных.

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с eps=0.4, min_samples=16
- Метрики: silhouette=0.195, DB=1.099, CH=1629.39
- Доля шума: 30.61% (2449 точек шума из 8000)
- Коротко: Несмотря на низкие абсолютные значения метрик, DBSCAN лучше отражает природу данных с шумом. KMeans вынужден распределять все точки по кластерам, что приводит к искусственному завышению числа кластеров (6).

### 4.3 Dataset C

- Лучший метод и параметры: KMeans с n_clusters=3, random_state=42
- Метрики: silhouette=0.316, DB=1.158, CH=6957.16
- AgglomerativeClustering показал silhouette=0.425 (лучше), но очень низкий CH=8.94 (хуже)
- Коротко: KMeans выбран по silhouette, хотя AgglomerativeClustering имел лучший silhouette score. Решение в пользу KMeans обосновано более сбалансированными метриками и интерпретируемостью 3 кластеров.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на данных с большим шумом (Dataset 2), где он вынужден создавать лишние кластеры для размещения выбросов
- DBSCAN выигрывает на данных с явным шумом и varying density, так как может корректно выделять шумовые точки
- AgglomerativeClustering показал противоречивые результаты: высокий silhouette но крайне низкий CH на Dataset 3, что требует дополнительной проверки
- Масштабирование оказалось критически важным для всех методов, особенно для KMeans и иерархической кластеризации

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: 5 запусков KMeans на Dataset 1 с разными random_state (42, 0, 123, 7, 99)
- Результаты: silhouette score варьировался в диапазоне 0.519-0.523, количество кластеров стабильно 2
- Вывод: KMeans показал высокую устойчивость на этом датасете благодаря четко разделенным кластерам. Стабильность результатов подтверждает адекватность выбора k=2.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через анализ средних значений признаков в каждом кластере
- Dataset 1: два кластера четко разделены по нескольким признакам, возможно представляют разные категории объектов
- Dataset 2: три кластера имеют перекрывающиеся распределения, что объясняет низкие значения метрик
- Dataset 3: три кластера показывают градиентное изменение значений признаков, возможно соответствуют разным уровням измеряемого параметра

## 6. Conclusion

1. Выбор метрики важен: silhouette наиболее информативен, но требует проверки другими метриками (DB, CH)
2. DBSCAN предпочтителен для данных с шумом, но требует тщательного подбора параметров
3. KMeans устойчив на хорошо разделенных данных, но плохо справляется с шумом и varying density
4. Метрики могут давать противоречивые оценки (как с AgglomerativeClustering), требуя экспертной интерпретации
5. Масштабирование признаков - обязательный шаг для корректного сравнения алгоритмов
6. Доля шума более 30% в реальных данных - распространенное явление
7. Визуализация (PCA, t-SNE) помогает понять причины успеха/провала алгоритмов
8. Unsupervised-эксперимент требует итеративного подхода: препроцессинг → кластеризация → оценка → интерпретация